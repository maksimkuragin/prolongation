# Prolongation
## Задача
Предсказание пролонгации автомобильной страховки. 
## Данные 
7600 размеченных объектов: из них 5300 одного класса, 2300 другого, и 3300 не размечаных данных, которые впоследствии необходимо было предсказать.
## Ход выполнения задачи 
1) Выгрузка и знакомство с данными. Первичный анализ показал, что есть пустые и пропущеные значения, от которых необходимо избавиться. 
2) Визуализация данных. Очевидно, что классы не сбалансированы, что гораздо больше данных по непролангированным клиентам. 
3) Упрощение данных. Удаление дублирующих фичей. Группировка категориальных значений, чтобы было меньше категориальных значений. 
4) Undersampled и Oversampled. Делаем Oversampled для сбалансировки классов. Теперь у нас 10500 данных для обучения. 
5) Подготовка данных к обучению. Делаем OneHotEncoder для категориальных фичей; конвертируем данные в Numpy; нормируем с помощью StandardScaler; разбиваем на train/test.
6) Обучение моделей. Для начала создадим несколько стандартных моделей и посмотрим по метрикам: Roc-Auc, Accuracy, F1-score на результат предсказаний тестовой выборки. Создаем модели: LogisticRegression, KNeighborsClassifier, DecisionTreeClassifier, SVM, RandomForestClassifier. Лучший результат на стандартных параметрах показал случайный лес, попробуем улучшить результат с помощью GridSearchCV. 
7) Предсказание на неразмеченных данных. Так как две модели (RandomForestClassifier и RandomForestClassifier с GridSearchCV) показали примерно одинаковый результат, сделаем предсказание обеими моделями. По итогу: две модели предсказали 3300 клиентов, не согласившись друг с другом в 140 случаях, а это меньше 5%. 
